# -*- coding: utf-8 -*-
"""Untitled16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1glbvijqAvZ7k2Ms3cPHeYI1-USTy44ou
"""

#chargement des biblioth√©ques
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import time
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, accuracy_score
import xgboost as xgb
from sklearn.metrics import confusion_matrix
import joblib
from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.ensemble import StackingClassifier

#chargement des donn√©es
df1=pd.read_csv("/content/drive/MyDrive/openfoodfacts_clean.csv")
df2=pd.read_csv("/content/drive/MyDrive/openfoodfacts_clean.xls")
#concat√©nation des donn√©es
data=pd.concat([df1,df2])

#exploration des donn√©es
print(data.head())
print(data.info())
print(data.describe())
print(data.shape)

#exploration des donn√©es 2
print(data.isnull().sum())
print(data. Name.duplicated().sum())
print(data.nunique())
print(data.describe(include='all'))

# Identifier le pourcentage de donn√©es manquantes
missing_percentage = (data.isnull().sum() / len(data)) * 100
print("\n--- Pourcentage de Valeurs Manquantes ---")
print(missing_percentage.sort_values(ascending=False).head(5))

#suppression des colonnes
col_supprimer = ['fruits‚Äö_l√©gumes_et_noix_-_s√©ch√©s ', 'prot√©ines']
df= data.drop(columns=col_supprimer, errors='ignore')

# Fonction de conversion bas√©e sur le bar√®me OFFICIEL (Solides)
def score(valeur):
    # 1. Gestion des valeurs nulles/vides
    if pd.isna(valeur) or valeur == '':
        return None

    valeur_str = str(valeur).strip().upper()

    # 2. Si c'est d√©j√† une lettre valide (A, B, C, D, E), on la garde
    if valeur_str in ['A', 'B', 'C', 'D', 'E']:
        return valeur_str

    # 3. Sinon, on essaie de convertir le chiffre en lettre
    try:
        score = float(valeur) # On convertit en nombre d√©cimal

        # Application des SEUILS OFFICIELS
        if score <= -1:
            return 'A'
        elif score <= 2:
            return 'B'
        elif score <= 10:
            return 'C'
        elif score <= 18:
            return 'D'
        else:
            return 'E'  # Score >= 19

    except ValueError:
        # Si ce n'est ni une lettre connue, ni un nombre convertible -> Poubelle
        return None

# --- Application au DataFrame ---

print("Distribution AVANT nettoyage :")
print(df['Nutriscore'].value_counts())

# Application de la fonction
df['Nutriscore']= df['Nutriscore'].apply(score)

# Suppression des lignes qui n'ont pas pu √™tre converties (None)
df = df.dropna(subset=['Nutriscore'])

print("\nDistribution APR√àS nettoyage (Bar√®me Officiel appliqu√©) :")
print(df['Nutriscore'].value_counts().sort_index())

#verification
print(df.shape)
df.head()

#remplacement des valeurs nulles
import pandas as pd

# 1. colonnes √† nettoyer
colonnes_nutriments = [
    'fibres_alimentaires',
    'acides_gras_satur√©s',
    'sucres',
    '√©nergie',
    'sel'
]

cols_presentes = [c for c in colonnes_nutriments if c in df.columns]

# 2. Imputation par la M√©diane
#  calcul de la m√©diane pour chaque colonne et on remplit les trous avec
print("--- Remplacement des valeurs manquantes par la M√©diane ---")
for col in cols_presentes:
    mediane = df[col].median()
    df[col] = df[col].fillna(mediane)
    print(f"Colonne '{col}' : NaN remplac√©s par la m√©diane ({mediane})")

# 3. Gestion de la colonne 'Name' (Texte)
# Pour le nom, on ne peut pas calculer de m√©diane, on met "Inconnu"
if 'Name' in df.columns:
    df['Name'] = df['Name'].fillna("Nom Inconnu")

# 4. V√©rification finale
print("\n--- V√©rification des Valeurs Manquantes Restantes ---")
print(df.isnull().sum())

#corr√©lation


# 1. Cr√©ation d'une copie pour l'analyse (pour ne pas toucher au dataset original)
df_corr = df.copy()

# 2. Encodage : A=0, B=1, C=2, D=3, E=4
mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}
df_corr['grade_numerique'] = df_corr['Nutriscore'].map(mapping)

# 3. S√©lection des colonnes num√©riques uniquement
cols_numeriques = df_corr.select_dtypes(include=['float64', 'int64', 'int32']).columns

# Calcul de la matrice de corr√©lation
correlation_matrix = df_corr[cols_numeriques].corr()

# Affichage des corr√©lations avec la cible (grade_numerique)
print("--- Corr√©lation avec le Nutri-Score (Plus c'est haut, plus c'est E) ---")
print(correlation_matrix['grade_numerique'].sort_values(ascending=False))

#visualisation du heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(
    correlation_matrix,
    annot=True,     # Affiche les chiffres dans les cases
    cmap='coolwarm', # Bleu = N√©gatif (Bon), Rouge = Positif (Mauvais)
    fmt=".2f",      # 2 chiffres apr√®s la virgule
    linewidths=0.5
)
plt.title("Matrice de Corr√©lation des Nutriments vs Nutri-Score")
plt.show()

df_corr.head()

#supression de la colonne name
#df=df.drop(columns='Name')
df=df.drop(columns='fruits‚Äö_l√©gumes_et_noix_-_s√©ch√©s')
df.head()

#verification des doublons
df.duplicated().any()
print(df.duplicated().sum())
print(df[df.duplicated()])
#suppression des doublons
dfs = df.drop_duplicates()
dfs.shape

#definition de features
X=dfs.drop(columns='Nutriscore')
y=dfs['Nutriscore']

#encodage de Y
mapping_nutriscore = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}
y_encoded = y.map(mapping_nutriscore)

#s√©paration du train/test
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)
print("\n--- S√©paration Termin√©e ---")
print(f"Donn√©es d'entra√Ænement (Train) : {X_train.shape}")
print(f"Donn√©es de test (Test)         : {X_test.shape}")

# Mod√©lisation
#Fonction d'Entra√Ænement et d'√âvaluation
def train_and_evaluate(name, model, X_train, y_train, X_test, y_test, target_names):
    """Entra√Æne un mod√®le, fait des pr√©dictions et affiche les m√©triques."""
    start_time = time.time()

    print(f"\n D√©marrage de l'entra√Ænement : {name}...")

    # Entra√Ænement
    model.fit(X_train, y_train)

    # Pr√©diction sur le jeu de test
    y_pred = model.predict(X_test)

    # √âvaluation
    accuracy = accuracy_score(y_test, y_pred)
    training_time = time.time() - start_time

    print(f" Termin√© en {training_time:.2f} secondes.")
    print("-" * 50)
    print(f"Pr√©cision Globale (Accuracy) : {accuracy:.4f}")

    # Rapport de classification d√©taill√©
    print("\n--- Rapport de Classification ---")
    print(classification_report(y_test, y_pred, target_names=target_names, zero_division=0))

    return model, accuracy, training_time

# D√©finition des Mod√®les
models_list = {
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),
    'Logistic Regression': LogisticRegression(max_iter=500, random_state=42, multi_class='multinomial', solver='lbfgs', n_jobs=-1),
    'K-Nearest Neighbors (KNN)': KNeighborsClassifier(n_neighbors=5, n_jobs=-1),
    'XGBoost': xgb.XGBClassifier(
        objective='multi:softmax',
        num_class=5,
        n_estimators=100,
        learning_rate=0.1,
        eval_metric='mlogloss',
        random_state=42,
        n_jobs=-1,

    )
}

# D√©finition des √©tiquettes (labels) pour le rapport
target_names = ['A', 'B', 'C', 'D', 'E']
# Entra√Ænement et V√©rification (Mod√®le par Mod√®le)
all_results = {}
trained_models = {}

for name, model in models_list.items():
    trained_model, accuracy, training_time = train_and_evaluate(
        name,
        model,
        X_train, y_train,
        X_test, y_test,
        target_names
    )

    all_results[name] = {'Accuracy': accuracy, 'Time': training_time}
    trained_models[name] = trained_model

# Affichage du tableau de synth√®se
print("\n" + "="*60)
print("             R√âSUM√â FINAL DES PERFORMANCES")
print("="*60)
final_summary = pd.DataFrame(all_results).T
final_summary['Rank'] = final_summary['Accuracy'].rank(ascending=False).astype(int)

print(final_summary.sort_values(by='Accuracy', ascending=False))

# 1. S√©lection du mod√®le champion
rf_model = trained_models['Random Forest']
y_pred_rf = rf_model.predict(X_test)

# 2. Calcul de la Matrice de Confusion
cm = confusion_matrix(y_test, y_pred_rf)

# 3. Visualisation
plt.figure(figsize=(8, 6))
sns.heatmap(
    cm,
    annot=True,
    fmt='d',
    cmap='Blues',
    xticklabels=target_names, # A, B, C, D, E pr√©dits
    yticklabels=target_names  # A, B, C, D, E r√©els
)
plt.title('Matrice de Confusion : Random Forest')
plt.xlabel('Pr√©diction')
plt.ylabel('Valeur R√©elle')
plt.show()

from sklearn.preprocessing import label_binarize

# 1. S√©lection du mod√®le champion (Random Forest)
rf_model_retenu = trained_models['Random Forest']

# 2. Obtenir les probabilit√©s de pr√©diction pour toutes les classes
y_pred_proba = rf_model_retenu.predict_proba(X_test)

# 3. Binariser les vraies √©tiquettes (y_test) pour la strat√©gie One-vs-Rest
n_classes = len(target_names)
y_test_binarized = label_binarize(y_test, classes=range(n_classes))

# 4. Tracer la courbe ROC pour chaque classe
plt.figure(figsize=(10, 8))
for i in range(n_classes):
    fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_pred_proba[:, i])
    auc = roc_auc_score(y_test_binarized[:, i], y_pred_proba[:, i])
    plt.plot(fpr, tpr, label=f"ROC curve for class {target_names[i]} (AUC = {auc:.3f})")

plt.plot([0, 1], [0, 1], 'k--', label='Random (AUC = 0.5)')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Multi-class ROC Curves (One-vs-Rest) - Random Forest")
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

#D√âFINITION ET ENTRA√éNEMENT DU CLASSIFICATEUR STACKING ---

print("\n--- 2. D√âFINITION ET ENTRA√éNEMENT ---")

# D√©finissez les mod√®les de base √† "stacker" (empiler)
base_estimators = [
    # Random Forest (Votre champion actuel)
    ('rf', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)),

    # XGBoost (Un mod√®le par boosting, pour la diversit√©)
    ('xgb', xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)),

    # K-Nearest Neighbors (KNN, un mod√®le de nature diff√©rente)
    ('knn', KNeighborsClassifier(n_neighbors=5, n_jobs=-1))
]

# L'estimateur final (m√©ta-mod√®le) prend les pr√©dictions des mod√®les de base
# comme input pour faire la pr√©diction finale.
final_estimator = LogisticRegression(multi_class='auto', solver='lbfgs', max_iter=1000, random_state=42)

# Initialisation du StackingClassifier
stack_model = StackingClassifier(
    estimators=base_estimators,
    final_estimator=final_estimator,
    cv=5, # Cross-Validation pour les pr√©dictions interm√©diaires
    n_jobs=-1 # Ex√©cution parall√®le des mod√®les de base
)

print("üß† Entra√Ænement du Stacking Classifier...")
# L'entra√Ænement inclut l'entra√Ænement des mod√®les de base et du m√©ta-mod√®le.
stack_model.fit(X_train, y_train)
print("‚úÖ Entra√Ænement termin√©.")

#  √âVALUATION ET COMPARAISON DES PERFORMANCES ---

print("\n--- 3. √âVALUATION DES PERFORMANCES ---")

y_pred = stack_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"üöÄ Pr√©cision du STACKING CLASSIFIER sur le jeu de test : {accuracy:.4f}")

# Comparaison avec les mod√®les de base individuels (pour s'assurer de l'am√©lioration)
print("\nComparaison avec les mod√®les de base :")
for name, model in base_estimators:
    # R√©-entra√Ænement n√©cessaire car Stacking utilise des versions clon√©es/pr√©train√©es
    model.fit(X_train, y_train)
    indiv_accuracy = accuracy_score(y_test, model.predict(X_test))
    print(f"  - Pr√©cision du mod√®le {name.upper()} : {indiv_accuracy:.4f}")


#SAUVEGARDE DU MOD√àLE CHAMPION (Le Stacking Classifier) ---

# C'est ce mod√®le que vous devriez utiliser dans votre API Flask !
NOM_FICHIER_STACKING = 'modele_nutriscore_stacking.joblib'
joblib.dump(stack_model, NOM_FICHIER_STACKING)

print(f"\n--- 4. SAUVEGARDE ET UTILISATION ---")
print(f"üíæ Le nouveau mod√®le champion (Stacking) a √©t√© sauvegard√© sous : {NOM_FICHIER_STACKING}")
